# mirror-neuron-frog-and-toad

# README: Supporting Artifacts for *Frog and Toad* Experiments

This document describes all files accompanying the **Frog and Toad** experiments, including data generation, labeling, training checkpoints, and final analysis scripts. Each archive represents a specific step or artifact in the workflow for replicating the dissertation’s results.

---

## 1. Overview

The artifacts in this repository follow a sequence matching the research pipeline, from raw game state generation to final AI model analysis:

1. **`0_python_files.tgz`**  
   - Contains **all Python scripts** for generating data, labeling states, training ANNs, and computing final metrics.  
   - Each sub-archive (e.g., `1_Generate_Game_States.tgz`, `2_Saved_Game_States.tgz`, etc.) corresponds to a step in the pipeline, **executed in numerical order** (1 through 8).

2. **`2_processed_game_states.zip`**  
   - Output from raw game state processing, **generated by** `1_Generate_Game_States/main.py`.

3. **`3_labeled_game_states.csv.zip`**  
   - **Labeled** game states after running `3_Labeling_Step/labler.py`.

4. **`4_split_game_states.tgz`**  
   - **Train/test splits** of the labeled dataset from `4_Split_Testing_Data/split_test_train.py`.

5. **`5_checkpoints.1.tgz`** and **`5_checkpoints.2.tgz`**  
   - **Complete model checkpoints** for various hyperparameter configurations.  
   - Each directory name encodes hyperparameters (date/time, activation function, batch size, dropout rate, etc.).

6. **`6_checkpoint_inference_activations.tgz`**  
   - **Neuron activation data** from inferences on the trained checkpoints.

7. **`7_statistical.plots.tgz`**  
   - **Statistical visualizations** (e.g., bar charts, box plots) of neuron activations and distribution metrics (mean, variance, skewness, kurtosis).

8. **`cmni_results.csv`**  
   - **CSV summary** of the final *Checkpoint Mirror Neuron Index (CMNI)* values computed for each model checkpoint.

---

## 2. Detailed Contents

### 2.1 `0_python_files.tgz`

When extracted, `python_files/` contains sub-archives for each stage of the workflow:

- **`1_Generate_Game_States/`**  
  - Scripts (`main.py`, `character.py`, `fandt.py`, etc.) for **generating raw game states** via random actions in *Frog and Toad*.

- **`2_Saved_Game_States/`**  
  - `main.py` for intermediate saving/processing of generated game states.

- **`3_Labeling_Step/`**  
  - `labler.py` **assigns optimal actions** (e.g., hop, jump, leap, help) to each state.

- **`4_Split_Testing_Data/`**  
  - `split_test_train.py` **divides labeled data** into training and testing sets.

- **`5_Pretraining/`**  
  - `pretrain.adaboost.py` (an example or alternative approach) for **training initial models**.

- **`6_Layer_Activations/`**  
  - `pretrain.inference.py` **collects neuron activation data** layer by layer from trained models.

- **`7_CMNI/`**  
  - Scripts like `compute_cmni.py`, `inference.py`, `plot_temporal_cmni.py` for **calculating the CMNI** and producing final metrics/visualizations.

**Usage:**
1. Extract with:  
   ```bash
   tar -xzf 0_python_files.tgz
   ```
2. Unpack each numbered sub-archive (1–8) and execute in order to replicate data generation, labeling, training, inference, and final metric computations.

### 2.2 `2_processed_game_states.zip`
- **Intermediate output** from `1_Generate_Game_States/main.py`, typically containing processed CSV or JSON data detailing each raw state.

### 2.3 `3_labeled_game_states.csv.zip`
- **Final labeled states** after running `labler.py` to determine optimal actions for each scenario.

### 2.4 `4_split_game_states.tgz`
- **Train/Test splits** produced by `split_test_train.py`, ensuring balanced coverage of each action label.

### 2.5 `5_checkpoints.1.tgz` and `5_checkpoints.2.tgz`
- **Trained models** from diverse hyperparameter experiments.  
- Expanding each archive reveals directories named by a **date/time** and **hyperparameter** string (e.g., `bs20` for batch size 20, `nl2` for 2 hidden layers, etc.). Each directory contains multiple `.h5` checkpoint files, one per epoch where validation loss improved.

### 2.6 `6_checkpoint_inference_activations.tgz`
- **Neuron activation data** from checkpoint inference. Typically arrays of per-neuron activation levels in each scenario, used to compute CMNI or generate stats.

### 2.7 `7_statistical.plots.tgz`
- **Visual plots** (PNG, PDF, etc.) representing statistical measures (mean, variance, kurtosis, skewness) for each neuron across the four \texttt{distress} scenarios.  

### 2.8 `cmni_results.csv`
- **Final CMNI** values for each checkpoint, summarizing mirror neuron-like activation strength.

---

## 3. Reproducing the Workflow

To fully replicate the pipeline:

1. **Extract Python Scripts**  
   ```bash
   tar -xzf 0_python_files.tgz
   ```
2. **Run in Numerical Order**  
   - **Step 1** → Generate raw game states (`main.py` in `1_Generate_Game_States/`).  
   - **Step 2** → Save/Process states (`2_Saved_Game_States/`).  
   - **Step 3** → Label each state (`3_Labeling_Step/labler.py`).  
   - **Step 4** → Create train/test splits (`4_Split_Testing_Data/split_test_train.py`).  
   - **Step 5** → Train the model(s) and produce checkpoints (`5_Pretraining/`).  
   - **Step 6** → Collect neuron activations from inference (`6_Layer_Activations/`).   
   - **Step 7** → Compute CMNI and create final charts (`7_CMNI/compute_cmni.py`, etc.).

3. **Use or Skip Training**  
   - **If re-training**: The script in step 5 will produce fresh checkpoint files.  
   - **If skipping training**: Expand `5_checkpoints.1.tgz` and `5_checkpoints.2.tgz` to load **existing** trained model checkpoints.

4. **Statistical Analysis**  
   - Combine the activation data from step 6 with scripts in step 8 to **generate CMNI metrics** and produce statistical plots.

---

## 4. Dependencies & Notes

- **Python**: Tested on Python 3.8+  
- **Libraries**: `TensorFlow` (or `Keras`), `NumPy`, `Pandas`, `Matplotlib`/`Seaborn`, etc.  
- **Hardware**:  
  - Generating six million states can be memory/CPU-intensive.  
  - Checkpoint inference and CMNI computations may also require substantial RAM.

---

## 5. Contact & Further Information

- **Methodology**: Refer to the *Methodology* and *Experimental Design* chapters in the dissertation for full details on usage, architecture, and parameter choices.  
- **Author**: Robyn Wyrick for questions or clarifications.

By following these steps and references, you should be able to replicate or extend the *Frog and Toad* experiments, verifying the emergence of mirror neuron-like patterns in artificial neural networks and exploring their implications for AI alignment.

**End of README**

